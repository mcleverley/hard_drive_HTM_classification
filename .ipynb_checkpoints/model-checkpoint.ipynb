{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#parameters\" data-toc-modified-id=\"parameters-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#encoder-size\" data-toc-modified-id=\"encoder-size-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>encoder size</a></span></li><li><span><a href=\"#encoders-needed:-5?\" data-toc-modified-id=\"encoders-needed:-5?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>encoders needed: 5?</a></span><ul class=\"toc-item\"><li><span><a href=\"#optional-strat:-drop-non-normalized-SMART-stats-and-try-again-(if-runtime-too-long),-since-we're-sort-of...-double-encoding,-almost\" data-toc-modified-id=\"optional-strat:-drop-non-normalized-SMART-stats-and-try-again-(if-runtime-too-long),-since-we're-sort-of...-double-encoding,-almost-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>optional strat: drop non-normalized SMART stats and try again (if runtime too long), since we're sort of... double encoding, almost</a></span></li><li><span><a href=\"#each-disk-has-a-serial_number-serving-as-unique-identifier\" data-toc-modified-id=\"each-disk-has-a-serial_number-serving-as-unique-identifier-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>each disk has a serial_number serving as unique identifier</a></span></li></ul></li></ul></li><li><span><a href=\"#class-imbalance-easing\" data-toc-modified-id=\"class-imbalance-easing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>class imbalance easing</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#quicker-pre-indexed-method\" data-toc-modified-id=\"quicker-pre-indexed-method-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>quicker pre-indexed method</a></span></li></ul></li><li><span><a href=\"#failure-horizons-complete\" data-toc-modified-id=\"failure-horizons-complete-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>failure horizons complete</a></span></li></ul></li><li><span><a href=\"#SP-+-TM-setup\" data-toc-modified-id=\"SP-+-TM-setup-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SP + TM setup</a></span></li><li><span><a href=\"#training-loop\" data-toc-modified-id=\"training-loop-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>training loop</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from htm.bindings.sdr import SDR, Metrics\n",
    "from htm.encoders.rdse import RDSE, RDSE_Parameters\n",
    "from htm.encoders.date import DateEncoder\n",
    "from htm.encoders import scalar_encoder\n",
    "from htm.encoders.scalar_encoder import ScalarEncoder, ScalarEncoderParameters\n",
    "from htm.bindings.algorithms import SpatialPooler\n",
    "from htm.bindings.algorithms import TemporalMemory\n",
    "from htm.algorithms.anomaly_likelihood import AnomalyLikelihood #FIXME use TM.anomaly instead, but it gives worse results than the py.AnomalyLikelihood now\n",
    "from htm.bindings.algorithms import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reorganizing for \"lifetime\" view...\n",
      "cleaning indices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('hard_disks.csv', \n",
    "                 index_col=0\n",
    "                )\n",
    "# df = df.drop(columns=['Unnamed: 0'])\n",
    "print('reorganizing for \"lifetime\" view...')\n",
    "df = df.sort_values(by=['date','serial_number']) # should it be serial_num then date? i wonder\n",
    "print('cleaning indices...')\n",
    "df = df.reset_index()\n",
    "df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters\n",
    "## encoder size\n",
    "encoder 'size' can be small since we're running 62 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "  # won't be using these exact params for each encoder, however.\n",
    " 'enc': {\n",
    "      \"value\" :\n",
    "         {'resolution': 0.88, 'size': 800, 'sparsity': 0.02},\n",
    "      \"time\": \n",
    "         {'timeOfDay': (30, 1), 'weekend': 21}\n",
    " },\n",
    " 'predictor': {'sdrc_alpha': 0.1},\n",
    " 'sp': {'boostStrength': 3.0,\n",
    "        'columnCount': 3200, # tweak this a little\n",
    "        'localAreaDensity': 0.04395604395604396,\n",
    "        'potentialPct': 0.85,\n",
    "        'synPermActiveInc': 0.04,\n",
    "        'synPermConnected': 0.13999999999999999,\n",
    "        'synPermInactiveDec': 0.006},\n",
    " 'tm': {'activationThreshold': 17,\n",
    "        'cellsPerColumn': 20,\n",
    "        'initialPerm': 0.21,\n",
    "        'maxSegmentsPerCell': 128,\n",
    "        'maxSynapsesPerSegment': 64,\n",
    "        'minThreshold': 10,\n",
    "        'newSynapseCount': 32,\n",
    "        'permanenceDec': 0.1,\n",
    "        'permanenceInc': 0.1},\n",
    " 'anomaly': {\n",
    "   'likelihood': \n",
    "       {#'learningPeriod': int(math.floor(self.probationaryPeriod / 2.0)),\n",
    "        #'probationaryPeriod': self.probationaryPeriod-default_parameters[\"anomaly\"][\"likelihood\"][\"learningPeriod\"],\n",
    "        'probationaryPct': 0.1,\n",
    "        'reestimationPeriod': 100} #These settings are copied from NAB\n",
    " }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoders needed: 5?\n",
    "- dateTime encoder to understand temporal sequence element\n",
    "- category encoder...? for the model\n",
    "    - could just convert each model to a number\n",
    "    - maybe RDSE does this for us, we'll see\n",
    "- scalar for capacity_bytes\n",
    "- one-bit encoder for 'failure' tacked on at the end, maybe.\n",
    "- SMART stat encoder\n",
    "\n",
    "maybe 4 encoders, we can use SMART_enc for capacity_bytes \n",
    "\n",
    "### optional strat: drop non-normalized SMART stats and try again (if runtime too long), since we're sort of... double encoding, almost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarts = [col for col in list(df.columns) if 'smart' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_encoder = DateEncoder(timeOfDay=(30,1), weekend=21) # less work is done on weekends\n",
    "# predict 'weekday vs weekend' HD consumption use to predict impending failure...?\n",
    "# maybe unnecessary, we'll see\n",
    "\n",
    "# SMART encoder\n",
    "stat_params = RDSE_Parameters()\n",
    "stat_params.size = 30 # this number is the one i'll be changing around the most\n",
    "stat_params.sparsity = 0.02 # the magic number\n",
    "stat_params.resolution = 0.88 \n",
    "stat_encoder = RDSE(stat_params) # create encoder\n",
    "# we could also use this for byte_capacity. model\n",
    "\n",
    "# failure 1-bit encoder to minimize SDR size. we only need one bit to encode 1 or 0, after all\n",
    "fail_params = ScalarEncoderParameters() \n",
    "fail_params.minimum = 0\n",
    "fail_params.maximum = 1\n",
    "fail_params.size = 30 # if i go under 30, it crashes: CHECK FAILED: \"args_.activeBits > 0u\" \n",
    "    # this is a pretty awful problem, considering i'm wasting 29 bits of calculation\n",
    "    # i'm probably missing some configuration in a setting somewhere\n",
    "fail_params.sparsity = 0.02\n",
    "# fail_params.resolution = 0.88\n",
    "fail_encoder = ScalarEncoder(fail_params) # it probably could just be a ScalarEncoder, not RDSE ...\n",
    "\n",
    "# # 5-bit scalar encoder for categorical \"model\" string, identifies unique hard disk.\n",
    "model_params = RDSE_Parameters() # in retrospect, naming one of the encoders 'model' isn't great nomenclature\n",
    "model_params.size = 30 # 5! will take care of 45 unique models\n",
    "model_params.sparsity = 0.02\n",
    "model_params.resolution = 0.88\n",
    "model_encoder = RDSE(model_params)\n",
    "\n",
    "# serial num encoder. 145,000 uniques\n",
    "serial_params = RDSE_Parameters() # in retrospect, naming one of the encoders 'model' isn't great nomenclature\n",
    "serial_params.size = 30 # 5! will take care of 45 unique models\n",
    "serial_params.sparsity = 0.02\n",
    "serial_params.resolution = 0.88\n",
    "serial_encoder = RDSE(serial_params)\n",
    "\n",
    "# calculate total bits in encoder\n",
    "# smart encoder is used 56 times (for SMART stats) and once for byte capacity\n",
    "encoder_width = date_encoder.size + stat_encoder.size*(len(smarts)+1) + fail_encoder.size \\\n",
    "+ model_encoder.size + serial_encoder.size\n",
    "encoder_info = Metrics([encoder_width], 999999999) # more 9s, the better\n",
    "\n",
    "\n",
    "\n",
    "# i was making a separate encoder for capacity_bytes, but it's 14 zeros and 30 bits from\n",
    "# STAT_encoder is already 10^32\n",
    "# mem_params = RDSE_Parameters\n",
    "# mem_params.size = 10 # max(df['capacity_bytes']) = 16000900661248. 14 zeros needs a deal of bits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each disk has a serial_number serving as unique identifier\n",
    "we've got 45 unique models and 144,876 unique hard_drives out of 12.5 million rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_2_normalized</th>\n",
       "      <th>smart_2_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "      <th>smart_199_raw</th>\n",
       "      <th>smart_200_normalized</th>\n",
       "      <th>smart_200_raw</th>\n",
       "      <th>smart_240_normalized</th>\n",
       "      <th>smart_240_raw</th>\n",
       "      <th>smart_241_normalized</th>\n",
       "      <th>smart_241_raw</th>\n",
       "      <th>smart_242_normalized</th>\n",
       "      <th>smart_242_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39086</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>S301NDVZ</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>1</td>\n",
       "      <td>117.0</td>\n",
       "      <td>142762888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38459.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.596416e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.416296e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93536</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ZCH098ER</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>34494144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19053.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.379076e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.637831e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104410</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>ZHZ3SS54</td>\n",
       "      <td>ST12000NM0008</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>93496976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.644411e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.569063e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137352</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>5641SFRFS</td>\n",
       "      <td>TOSHIBA MQ01ABF050</td>\n",
       "      <td>500107862016</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194389</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>ZA120V8D</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>216744360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29234.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.230961e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.917249e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12077347</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>57RFWNHJT</td>\n",
       "      <td>TOSHIBA MQ01ABF050</td>\n",
       "      <td>500107862016</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12117280</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>Z302DJW1</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4000787030016</td>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>5679912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>45380.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.669282e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.049333e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12286683</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>ZA14EBBG</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>155947482.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28651.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.762404e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.168453e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12295966</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>ZA1819EP</td>\n",
       "      <td>ST8000NM0055</td>\n",
       "      <td>8001563222016</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>32634152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25265.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.249917e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.831933e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12346442</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>ZJV3BTAZ</td>\n",
       "      <td>ST12000NM0007</td>\n",
       "      <td>12000138625024</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>32211586.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.198867e+10</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.016082e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date serial_number               model  capacity_bytes  \\\n",
       "39086     2020-04-01      S301NDVZ         ST4000DM000   4000787030016   \n",
       "93536     2020-04-01      ZCH098ER       ST12000NM0007  12000138625024   \n",
       "104410    2020-04-01      ZHZ3SS54       ST12000NM0008  12000138625024   \n",
       "137352    2020-04-02     5641SFRFS  TOSHIBA MQ01ABF050    500107862016   \n",
       "194389    2020-04-02      ZA120V8D        ST8000NM0055   8001563222016   \n",
       "...              ...           ...                 ...             ...   \n",
       "12077347  2020-06-28     57RFWNHJT  TOSHIBA MQ01ABF050    500107862016   \n",
       "12117280  2020-06-28      Z302DJW1         ST4000DM000   4000787030016   \n",
       "12286683  2020-06-29      ZA14EBBG        ST8000NM0055   8001563222016   \n",
       "12295966  2020-06-29      ZA1819EP        ST8000NM0055   8001563222016   \n",
       "12346442  2020-06-29      ZJV3BTAZ       ST12000NM0007  12000138625024   \n",
       "\n",
       "          failure  smart_1_normalized  smart_1_raw  smart_2_normalized  \\\n",
       "39086           1               117.0  142762888.0                 NaN   \n",
       "93536           1                75.0   34494144.0                 NaN   \n",
       "104410          1                69.0   93496976.0                 NaN   \n",
       "137352          1               100.0          0.0               100.0   \n",
       "194389          1                83.0  216744360.0                 NaN   \n",
       "...           ...                 ...          ...                 ...   \n",
       "12077347        1               100.0          0.0               100.0   \n",
       "12117280        1               103.0    5679912.0                 NaN   \n",
       "12286683        1                51.0  155947482.0                 NaN   \n",
       "12295966        1                55.0   32634152.0                 NaN   \n",
       "12346442        1                72.0   32211586.0                 NaN   \n",
       "\n",
       "          smart_2_raw  smart_3_normalized  ...  smart_199_normalized  \\\n",
       "39086             NaN                91.0  ...                 200.0   \n",
       "93536             NaN                90.0  ...                 200.0   \n",
       "104410            NaN                97.0  ...                 200.0   \n",
       "137352            0.0               100.0  ...                 200.0   \n",
       "194389            NaN                89.0  ...                 200.0   \n",
       "...               ...                 ...  ...                   ...   \n",
       "12077347          0.0               100.0  ...                 200.0   \n",
       "12117280          NaN                94.0  ...                 200.0   \n",
       "12286683          NaN                89.0  ...                 200.0   \n",
       "12295966          NaN                91.0  ...                 200.0   \n",
       "12346442          NaN                92.0  ...                 200.0   \n",
       "\n",
       "          smart_199_raw  smart_200_normalized  smart_200_raw  \\\n",
       "39086               0.0                   NaN            NaN   \n",
       "93536               0.0                 100.0            0.0   \n",
       "104410              0.0                 100.0            0.0   \n",
       "137352              0.0                   NaN            NaN   \n",
       "194389              0.0                   NaN            NaN   \n",
       "...                 ...                   ...            ...   \n",
       "12077347            0.0                   NaN            NaN   \n",
       "12117280            0.0                   NaN            NaN   \n",
       "12286683            0.0                   NaN            NaN   \n",
       "12295966            0.0                   NaN            NaN   \n",
       "12346442            0.0                 100.0            0.0   \n",
       "\n",
       "          smart_240_normalized  smart_240_raw  smart_241_normalized  \\\n",
       "39086                    100.0        38459.0                 100.0   \n",
       "93536                    100.0        19053.0                 100.0   \n",
       "104410                   100.0         3021.0                 100.0   \n",
       "137352                   100.0            0.0                   NaN   \n",
       "194389                   100.0        29234.0                 100.0   \n",
       "...                        ...            ...                   ...   \n",
       "12077347                 100.0            0.0                   NaN   \n",
       "12117280                 100.0        45380.0                 100.0   \n",
       "12286683                 100.0        28651.0                 100.0   \n",
       "12295966                 100.0        25265.0                 100.0   \n",
       "12346442                 100.0         6659.0                 100.0   \n",
       "\n",
       "          smart_241_raw  smart_242_normalized  smart_242_raw  \n",
       "39086      5.596416e+10                 100.0   2.416296e+11  \n",
       "93536      6.379076e+10                 100.0   1.637831e+11  \n",
       "104410     3.644411e+10                 100.0   5.569063e+10  \n",
       "137352              NaN                   NaN            NaN  \n",
       "194389     7.230961e+10                 100.0   1.917249e+11  \n",
       "...                 ...                   ...            ...  \n",
       "12077347            NaN                   NaN            NaN  \n",
       "12117280   6.669282e+10                 100.0   2.049333e+11  \n",
       "12286683   6.762404e+10                 100.0   2.168453e+11  \n",
       "12295966   6.249917e+10                 100.0   1.831933e+11  \n",
       "12346442   5.198867e+10                 100.0   1.016082e+11  \n",
       "\n",
       "[314 rows x 61 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['failure']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class imbalance easing\n",
    "- borrowing that guy's solution (in EDA notebook) of 'failure horizons'. if a failure occurs, append failure=1 to the past 7 days of that drive's rows. pre-sorting the drives by date & serial number helps here.\n",
    "- iterating through the whole DF is computationally pricy\n",
    "    - instead, collect failure indexes by subsetting where failure==1\n",
    "        - append to list\n",
    "        - loop through list, adding X-7, X-6... for every index X to create failure horizons\n",
    "        - then loop through the list of indexes and use df.at[indx, colname] = value\n",
    "            - this saves a lot of copy-warning headaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quicker pre-indexed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failure indexes collected\n",
      "failure horizon indexes drawn\n"
     ]
    }
   ],
   "source": [
    "fails = df[df['failure']==1]\n",
    "inds = list(fails.index)\n",
    "print('failure indexes collected')\n",
    "\n",
    "horizons = [] \n",
    "for ind in inds: # indexes with current failures\n",
    "    for b in range(-7, 0):\n",
    "        horizons.append(b+ind) # append the last 7 days\n",
    "    horizons.append(ind) # append the day\n",
    "print('failure horizon indexes drawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(horizons)-314) / 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final failure count: 2512\n"
     ]
    }
   ],
   "source": [
    "for h in horizons:\n",
    "    # df.at or df.set_value is even faster than df.ix\n",
    "    df.at[h, 'failure'] = 1\n",
    "print('final failure count: ' + str(len(df[df['failure']==1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## failure horizons complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SP + TM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial pooler\n",
    "spParams = parameters['sp']\n",
    "sp = SpatialPooler(\n",
    "    inputDimensions            = (encodingWidth,),\n",
    "    columnDimensions           = (spParams[\"columnCount\"],),\n",
    "    potentialPct               = spParams[\"potentialPct\"],\n",
    "    potentialRadius            = encodingWidth,\n",
    "    globalInhibition           = True,\n",
    "    localAreaDensity           = spParams[\"localAreaDensity\"],\n",
    "    synPermInactiveDec         = spParams[\"synPermInactiveDec\"],\n",
    "    synPermActiveInc           = spParams[\"synPermActiveInc\"],\n",
    "    synPermConnected           = spParams[\"synPermConnected\"],\n",
    "    boostStrength              = spParams[\"boostStrength\"],\n",
    "    wrapAround                 = True\n",
    ")\n",
    "sp_info = Metrics(sp.getColumnDimensions(), 999999999)\n",
    "\n",
    "# temporal memory to help model understand 'lifetime' progression of hard drive\n",
    "tmParams = parameters['tm']\n",
    "tm = TemporalMemory(\n",
    "    columnDimensions          = (spParams[\"columnCount\"],),\n",
    "    cellsPerColumn            = tmParams[\"cellsPerColumn\"], # 13\n",
    "    activationThreshold       = tmParams[\"activationThreshold\"], # 17\n",
    "    initialPermanence         = tmParams[\"initialPerm\"], # 0.21\n",
    "    connectedPermanence       = spParams[\"synPermConnected\"],\n",
    "    minThreshold              = tmParams[\"minThreshold\"], # 19\n",
    "    maxNewSynapseCount        = tmParams[\"newSynapseCount\"], # 32\n",
    "    permanenceIncrement       = tmParams[\"permanenceInc\"], # 0.1\n",
    "    permanenceDecrement       = tmParams[\"permanenceDec\"], # 0.1\n",
    "    predictedSegmentDecrement = 0.0,\n",
    "    maxSegmentsPerCell        = tmParams[\"maxSegmentsPerCell\"], # 128\n",
    "    maxSynapsesPerSegment     = tmParams[\"maxSynapsesPerSegment\"] # 64\n",
    ")\n",
    "tm_info = Metrics( [tm.numberOfCells()], 999999999)\n",
    "\n",
    "# anomaly prediction\n",
    "anParams = parameters['anomaly']['likelihood']\n",
    "probationaryPeriod = int(math.floor(float(anParams['probationaryPct'])*len(df)))\n",
    "learningPeriod = int(math.floor(probationaryPeriod / 2.0))\n",
    "anomaly_history = AnomalyLikelihood(learningPeriod = learningPeriod,\n",
    "       estimationSamples = probationaryPeriod - learningPeriod,\n",
    "       reestimationPeriod = anParams['reestimationPeriod'])\n",
    "future_length = [i+1 for i in range(3)]\n",
    "predictor = Predictor(steps=future_length, alpha=parameters['predictor']['sdrc_alpha'])\n",
    "predictor_resolution = 1 # divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look 3 days ahead\n",
    "future_length = [i+1 for i in range(3)]\n",
    "future_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i+1 for i in range(3)]\n",
    "b = [[] for e in a]\n",
    "predictions = dict(zip(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(future_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'serial_number',\n",
       " 'model',\n",
       " 'capacity_bytes',\n",
       " 'failure',\n",
       " 'smart_1_normalized',\n",
       " 'smart_1_raw',\n",
       " 'smart_2_normalized',\n",
       " 'smart_2_raw',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_normalized',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_7_raw',\n",
       " 'smart_8_normalized',\n",
       " 'smart_8_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_10_normalized',\n",
       " 'smart_10_raw',\n",
       " 'smart_12_normalized',\n",
       " 'smart_12_raw',\n",
       " 'smart_184_normalized',\n",
       " 'smart_184_raw',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized',\n",
       " 'smart_188_raw',\n",
       " 'smart_189_normalized',\n",
       " 'smart_189_raw',\n",
       " 'smart_190_normalized',\n",
       " 'smart_190_raw',\n",
       " 'smart_191_normalized',\n",
       " 'smart_191_raw',\n",
       " 'smart_192_normalized',\n",
       " 'smart_192_raw',\n",
       " 'smart_193_normalized',\n",
       " 'smart_193_raw',\n",
       " 'smart_194_normalized',\n",
       " 'smart_194_raw',\n",
       " 'smart_195_normalized',\n",
       " 'smart_195_raw',\n",
       " 'smart_196_normalized',\n",
       " 'smart_196_raw',\n",
       " 'smart_197_normalized',\n",
       " 'smart_197_raw',\n",
       " 'smart_198_normalized',\n",
       " 'smart_198_raw',\n",
       " 'smart_199_normalized',\n",
       " 'smart_199_raw',\n",
       " 'smart_200_normalized',\n",
       " 'smart_200_raw',\n",
       " 'smart_240_normalized',\n",
       " 'smart_240_raw',\n",
       " 'smart_241_normalized',\n",
       " 'smart_241_raw',\n",
       " 'smart_242_normalized',\n",
       " 'smart_242_raw']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training...')\n",
    "\n",
    "# training parameters\n",
    "\n",
    "# future_length = [i+1 for i in range(3)] \n",
    "    # how 'deep' into the future to predict\n",
    "    # this is set before when we initialize the predictor object (after sp+tm)\n",
    "learning_thresh = len(df)/300 # number of rows after which to begin predicting\n",
    "# input and anomaly holders\n",
    "inputs = []\n",
    "anomaly = []\n",
    "anomalyProb = []\n",
    "# prediction dictionary\n",
    "lengths = [i+1 for i in range(future_length)]\n",
    "holders = [[] for l in lengths]\n",
    "predictions = dict(zip(lengths, holders))\n",
    "leng = len(df)\n",
    "\n",
    "predictor.reset()\n",
    "for i, row in tqdm_notebook(df.iterrows()): # row-by-row feed \n",
    "        # create encoding, piece by piece then concatenate\n",
    "    # dateTime\n",
    "    pieces = []\n",
    "    date = date_encoder(row['date'])\n",
    "    pieces.append(date)\n",
    "    # serial number\n",
    "    serial = serial_encoder(row['serial_number'])\n",
    "    pieces.append(serial)\n",
    "    # failure\n",
    "    fail = fail_encoder(row['failure'])\n",
    "    pieces.append(fail)\n",
    "    # model number\n",
    "    model = model_encoder(row['model'])\n",
    "    pieces.append(model)\n",
    "    # byte capacity\n",
    "    capacity = stat_encoder(row['capacity_bytes']) # use SMART stat encoder for this one due to numerical similarity\n",
    "    pieces.append(capacity)\n",
    "    # SMART statistics\n",
    "    for stat in smarts: # 56 of these, raw and normalized\n",
    "        stat_encoding = stat_encoder(row[stat])\n",
    "        pieces.append(stat_encoding)\n",
    "        \n",
    "    # string each bit-encoded feature into a final encoding SDR\n",
    "    encoding = SDR(encodingWidth).concatenate([pieces])\n",
    "    enc_info.addData(encoding)\n",
    "    \n",
    "    # pass encoding into spatial pooler\n",
    "    active_cols = SDR(sp.getColumnDimensions())\n",
    "    sp.compute(encoding, True, activeColumns) # learn = True\n",
    "    \n",
    "    # feed pooled SDR into temporal memory\n",
    "    neuron_state = tm.getActiveCells()\n",
    "    tm_info.addData(neuron_state.flatten())\n",
    "    tm.compute(neuron_state, learn=True)\n",
    "    \n",
    "    if i < learning_thresh: # if TM hasn't seen enough data to make a good prediction yet\n",
    "        continue # skip to the next row of loop\n",
    "    \n",
    "    # predict X steps into future\n",
    "    post_learn_neuron_state = tm.getActiveCells() # separate for clarity\n",
    "    pdf = predictor.infer(post_learn_neuron_state)\n",
    "    for n in tuple(future_length):\n",
    "        if pdf[n]: # if prediction was made\n",
    "            predictions[n].append(np.argmax(pdf[n])*predictor_resolution) # *1\n",
    "        else:\n",
    "            predictions[n].append(float('nan')) # no prediction\n",
    "    \n",
    "    # don't forget to predictor.reset() when you reach the end of one disk's lifetime\n",
    "    \n",
    "    # can't we skip the pre-training by saying \"only predict if i > len(df)/30?\"\n",
    "    # that should take care of 'must call learn before infer' errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    # list of SMART-stat column names\n",
    "    pre_stats = SDR(encodingWidth - (len(smarts)*stat_encoder.size).concatenate(\n",
    "    [date, serial, fail, model, capacity]) # incomplete encoding\n",
    "                    #\n",
    "        \n",
    "    for stat in smarts: # 56 of these (raw and normalized)\n",
    "        stat_enc = stat_encoder(row[stat])\n",
    "        \n",
    "    encoding = SDR(encodingWidth).concatenate([p])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_encoder = DateEncoder(timeOfDay=(30,1), weekend=21) # less work is done on weekends\n",
    "# predict 'weekday vs weekend' HD consumption use to predict impending failure...?\n",
    "# maybe unnecessary, we'll see\n",
    "\n",
    "# SMART encoder\n",
    "stat_params = RDSE_Parameters()\n",
    "stat_params.size = 30 # this number is the one i'll be changing around the most\n",
    "stat_params.sparsity = 0.02 # the magic number\n",
    "stat_params.resolution = 0.88 \n",
    "stat_encoder = RDSE(stat_params) # create encoder\n",
    "# we could also use this for byte_capacity. model\n",
    "\n",
    "# failure 1-bit encoder to minimize SDR size. we only need one bit to encode 1 or 0, after all\n",
    "fail_params = ScalarEncoderParameters() \n",
    "fail_params.minimum = 0\n",
    "fail_params.maximum = 1\n",
    "fail_params.size = 30 # if i go under 30, it crashes: CHECK FAILED: \"args_.activeBits > 0u\" \n",
    "    # this is a pretty awful problem, considering i'm wasting 29 bits of calculation\n",
    "    # i'm probably missing some configuration in a setting somewhere\n",
    "fail_params.sparsity = 0.02\n",
    "# fail_params.resolution = 0.88\n",
    "fail_encoder = ScalarEncoder(fail_params) # it probably could just be a ScalarEncoder, not RDSE ...\n",
    "\n",
    "# # 5-bit scalar encoder for categorical \"model\" string, identifies unique hard disk.\n",
    "model_params = RDSE_Parameters() # in retrospect, naming one of the encoders 'model' isn't great nomenclature\n",
    "model_params.size = 30 # 5! will take care of 45 unique models\n",
    "model_params.sparsity = 0.02\n",
    "model_params.resolution = 0.88\n",
    "model_encoder = RDSE(model_params)\n",
    "\n",
    "# serial num encoder. 145,000 uniques\n",
    "serial_params = RDSE_Parameters() # in retrospect, naming one of the encoders 'model' isn't great nomenclature\n",
    "serial_params.size = 30 # 5! will take care of 45 unique models\n",
    "serial_params.sparsity = 0.02\n",
    "serial_params.resolution = 0.88\n",
    "serial_encoder = RDSE(serial_params)\n",
    "\n",
    "# calculate total bits in encoder\n",
    "# smart encoder is used 56 times (for SMART stats) and once for byte capacity\n",
    "encoder_width = date_encoder.size + stat_encoder.size*(len(smarts)+1) + fail_encoder.size \\\n",
    "+ model_encoder.size + serial_encoder.size\n",
    "encoder_info = Metrics([encoder_width], 999999999) # more 9s, the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart_1_normalized',\n",
       " 'smart_1_raw',\n",
       " 'smart_2_normalized',\n",
       " 'smart_2_raw',\n",
       " 'smart_3_normalized',\n",
       " 'smart_3_raw',\n",
       " 'smart_4_normalized',\n",
       " 'smart_4_raw',\n",
       " 'smart_5_normalized',\n",
       " 'smart_5_raw',\n",
       " 'smart_7_normalized',\n",
       " 'smart_7_raw',\n",
       " 'smart_8_normalized',\n",
       " 'smart_8_raw',\n",
       " 'smart_9_normalized',\n",
       " 'smart_9_raw',\n",
       " 'smart_10_normalized',\n",
       " 'smart_10_raw',\n",
       " 'smart_12_normalized',\n",
       " 'smart_12_raw',\n",
       " 'smart_184_normalized',\n",
       " 'smart_184_raw',\n",
       " 'smart_187_normalized',\n",
       " 'smart_187_raw',\n",
       " 'smart_188_normalized',\n",
       " 'smart_188_raw',\n",
       " 'smart_189_normalized',\n",
       " 'smart_189_raw',\n",
       " 'smart_190_normalized',\n",
       " 'smart_190_raw',\n",
       " 'smart_191_normalized',\n",
       " 'smart_191_raw',\n",
       " 'smart_192_normalized',\n",
       " 'smart_192_raw',\n",
       " 'smart_193_normalized',\n",
       " 'smart_193_raw',\n",
       " 'smart_194_normalized',\n",
       " 'smart_194_raw',\n",
       " 'smart_195_normalized',\n",
       " 'smart_195_raw',\n",
       " 'smart_196_normalized',\n",
       " 'smart_196_raw',\n",
       " 'smart_197_normalized',\n",
       " 'smart_197_raw',\n",
       " 'smart_198_normalized',\n",
       " 'smart_198_raw',\n",
       " 'smart_199_normalized',\n",
       " 'smart_199_raw',\n",
       " 'smart_200_normalized',\n",
       " 'smart_200_raw',\n",
       " 'smart_240_normalized',\n",
       " 'smart_240_raw',\n",
       " 'smart_241_normalized',\n",
       " 'smart_241_raw',\n",
       " 'smart_242_normalized',\n",
       " 'smart_242_raw']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "714.886px",
    "left": "841.368px",
    "top": "53.423px",
    "width": "193.182px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
